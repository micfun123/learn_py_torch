{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self,csv_file,transform=None,is_test=False):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)  #return the total number of samples in the dataset.\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data_frame.iloc[index]\n",
    "\n",
    "        if self.is_test:\n",
    "            image = item.values.reshape(28,28).astype(np.uint8)\n",
    "            label = None\n",
    "        else:\n",
    "            image = item[1:].values.reshape(28,28).astype(np.uint8)\n",
    "            label = item.iloc[0]\n",
    "\n",
    "        image = transforms.ToPILImage()(image)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_test:\n",
    "            return image\n",
    "        else:\n",
    "            return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomRotation(15),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5),)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomMNISTDataset(csv_file='train.csv',transform=transform,is_test=False)\n",
    "test_dataset = CustomMNISTDataset(csv_file='test.csv',transform=transform,is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 42000 Test Size: 28000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Size: {len(train_dataset)} Test Size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.8588, -0.7647,  0.0745,\n",
       "            0.0745,  0.5059, -0.3255, -0.4353, -0.9922, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.8745, -0.8980, -0.3255,  0.9608,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.7020,  0.9294,  0.1843, -0.7490, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.4353,  0.4039,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922, -0.7490, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.5216,  0.4980,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.8118, -0.5765,\n",
       "           -0.8824, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            0.3490,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "           -0.1451, -0.3490,  0.5608,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "           -0.1843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922,  0.3647,\n",
       "            0.9922,  0.9922,  0.9922,  0.5843,  0.1529,  0.1529, -0.6471,\n",
       "           -1.0000, -0.9137, -0.7725,  0.5686,  0.9922,  0.9922,  0.9059,\n",
       "           -0.3333, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6314,  0.9922,\n",
       "            0.9922,  0.9922, -0.3020, -0.4745, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000,  0.0039,  0.9765,  0.9922,  0.9922,\n",
       "            0.3412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3725,  0.9922,\n",
       "            0.9922,  0.8824, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.3490,  0.9922,  0.9922,\n",
       "            0.6627, -0.4039, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4980,  0.9922,\n",
       "            0.9922,  0.4588, -0.8118, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.8039,  0.9922,  0.9922,\n",
       "            0.9922,  0.2000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.8902,  0.8196,  0.9922,\n",
       "            0.9922,  0.9922, -0.9451, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8824,  0.9922,\n",
       "            0.9922,  0.2000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.8588,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3020,  0.9922,\n",
       "            0.9922,  0.7569, -0.9059, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.9843,  0.2784,  0.9922,\n",
       "            0.9922,  0.9922, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4118,  0.9922,\n",
       "            0.9922,  0.9922, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.2627,  0.9922,\n",
       "            0.9922,  0.9922, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6235,  0.9922,\n",
       "            0.9922,  0.9922, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8824,  0.6157,\n",
       "            0.9922,  0.9922,  0.5686, -0.9059, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.8745, -0.6235,  0.9922,\n",
       "            0.9922,  0.9922, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5294,\n",
       "            0.6627,  0.9922,  0.9922,  0.5843, -0.4824, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -0.8353,  0.2627,  0.6392,  0.9922,\n",
       "            0.9922,  0.1765, -0.9922, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3255,\n",
       "            0.9059,  0.9922,  0.9922,  0.5216, -0.6235, -0.6235, -0.7333,\n",
       "           -0.6784, -0.6235,  0.6392,  0.9922,  0.9922,  0.9922,  0.9216,\n",
       "           -0.7569, -0.7569, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.1059,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.8275,\n",
       "            0.9059,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.3412,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.8980,  0.4275,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.8745,  0.9922, -0.3255,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000,  0.4275,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9059, -0.4510, -0.3255, -0.9137,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.9373, -0.4039,  0.1451,  0.9922,  1.0000,  0.9922,\n",
       "            1.0000,  0.1451, -0.8510, -0.8824, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False) # num_workers=2 slows down the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgpElEQVR4nO3de3CU5dnH8d8CYTmYLAbISQImoCBysOUQMiAGyRBS6wCi4qEjOA4WDI6AiI2jHFrnTcUKjIrgtEpkFEUcAtVaHAWTvNokCEoZqqZJGgSEBMEhG4IEJM/7B69bVxJwl02uHL6fmZ0hu8+dvXi67bdPdnPjchzHEQAATayd9QAAgLaJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABl2jfvn1yuVz605/+FLLvmZubK5fLpdzc3JB9T6C5IUBok7Kzs+VyubRz507rURrN119/rdtvv13dunVTRESEJk2apP/85z/WYwE+HawHABB6J06c0Lhx41RVVaXHHntMYWFhWrFihW644Qbt3r1b3bt3tx4RIEBAa/TCCy+opKREO3bs0IgRIyRJ6enpGjRokJ555hn9z//8j/GEAD+CAxp0+vRpLVq0SMOGDZPH41HXrl11/fXX68MPP2xwzYoVK9SnTx917txZN9xwg/bu3XveMV9++aVuvfVWRUZGqlOnTho+fLj++te/XnSekydP6ssvv9TRo0cveuxbb72lESNG+OIjSQMGDND48eP15ptvXnQ90BQIENAAr9erv/zlL0pJSdFTTz2lJUuW6JtvvlFaWpp279593vHr1q3Ts88+q4yMDGVmZmrv3r268cYbVVlZ6TvmX//6l0aNGqUvvvhCv/vd7/TMM8+oa9eumjx5snJyci44z44dO3TNNdfo+eefv+BxdXV12rNnj4YPH37eYyNHjlRZWZmqq6t/3kkAGhE/ggMacPnll2vfvn3q2LGj776ZM2dqwIABeu655/TSSy/5HV9aWqqSkhJdccUVkqSJEycqKSlJTz31lJYvXy5Jeuihh9S7d2998skncrvdkqQHHnhAY8aM0aOPPqopU6Zc8tzffvutamtrFRsbe95jP9x36NAh9e/f/5KfC7gUXAEBDWjfvr0vPnV1dfr222/1/fffa/jw4fr000/PO37y5Mm++EjnrjaSkpL07rvvSjoXhu3bt+v2229XdXW1jh49qqNHj+rYsWNKS0tTSUmJvv766wbnSUlJkeM4WrJkyQXn/u677yTJF7gf69Spk98xgCUCBFzAK6+8oiFDhqhTp07q3r27evbsqb/97W+qqqo679irrrrqvPuuvvpq7du3T9K5KyTHcfTEE0+oZ8+efrfFixdLko4cOXLJM3fu3FmSVFtbe95jp06d8jsGsMSP4IAGvPrqq5oxY4YmT56sRx55RFFRUWrfvr2ysrJUVlYW8Perq6uTJC1YsEBpaWn1HtOvX79LmlmSIiMj5Xa7dfjw4fMe++G+uLi4S34e4FIRIKABb731lhITE7Vp0ya5XC7f/T9crfxUSUnJeff9+9//1pVXXilJSkxMlCSFhYUpNTU19AP/v3bt2mnw4MH1/pJtUVGREhMTFR4e3mjPD/xc/AgOaED79u0lSY7j+O4rKipSQUFBvcdv3rzZ7z2cHTt2qKioSOnp6ZKkqKgopaSk6MUXX6z36uSbb7654DyBfAz71ltv1SeffOIXoeLiYm3fvl233XbbRdcDTYErILRpL7/8srZu3Xre/Q899JB+/etfa9OmTZoyZYpuuukmlZeXa82aNRo4cKBOnDhx3pp+/fppzJgxmj17tmpra7Vy5Up1795dCxcu9B2zatUqjRkzRoMHD9bMmTOVmJioyspKFRQU6ODBg/rnP//Z4Kw7duzQuHHjtHjx4ot+EOGBBx7Qn//8Z910001asGCBwsLCtHz5ckVHR+vhhx/++ScIaEQECG3a6tWr671/xowZmjFjhioqKvTiiy/qvffe08CBA/Xqq69q48aN9W4Ses8996hdu3ZauXKljhw5opEjR+r555/3+zj0wIEDtXPnTi1dulTZ2dk6duyYoqKi9Itf/EKLFi0K2d8rPDxcubm5mjdvnp588knV1dUpJSVFK1asUM+ePUP2PMClcDk//vkCAABNhPeAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEw0u98Dqqur06FDhxQeHu63/QkAoGVwHEfV1dWKi4tTu3YNX+c0uwAdOnRI8fHx1mMAAC7RgQMH1KtXrwYfb3YB+mGTxDH6lToozHgaAECgvtcZfaR3L7rpbaMFaNWqVXr66adVUVGhoUOH6rnnntPIkSMvuu6HH7t1UJg6uAgQALQ4/7+/zsXeRmmUDyFs2LBB8+fP1+LFi/Xpp59q6NChSktLC8k/tgUAaB0aJUDLly/XzJkzde+992rgwIFas2aNunTpopdffrkxng4A0AKFPECnT5/Wrl27/P7BrXbt2ik1NbXef0eltrZWXq/X7wYAaP1CHqCjR4/q7Nmzio6O9rs/OjpaFRUV5x2flZUlj8fju/EJOABoG8x/ETUzM1NVVVW+24EDB6xHAgA0gZB/Cq5Hjx5q3769Kisr/e6vrKxUTEzMece73W653e5QjwEAaOZCfgXUsWNHDRs2TNu2bfPdV1dXp23btik5OTnUTwcAaKEa5feA5s+fr+nTp2v48OEaOXKkVq5cqZqaGt17772N8XQAgBaoUQI0bdo0ffPNN1q0aJEqKip03XXXaevWred9MAEA0Ha5HMdxrIf4Ma/XK4/HoxRNYicEAGiBvnfOKFdbVFVVpYiIiAaPM/8UHACgbSJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmOlgPADSG0hWjglpXNm1NiCcJnXu+Ghvwmo8LBwb1XHH5TsBruuQUBfVcaLu4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATLAZKdBCrOuTH/iiYNZI0rQg1qwKfEnfDbMCXtNvXmHgT4RmiSsgAIAJAgQAMBHyAC1ZskQul8vvNmDAgFA/DQCghWuU94CuvfZaffDBB/99kg681QQA8NcoZejQoYNiYmIa41sDAFqJRnkPqKSkRHFxcUpMTNTdd9+t/fv3N3hsbW2tvF6v3w0A0PqFPEBJSUnKzs7W1q1btXr1apWXl+v6669XdXV1vcdnZWXJ4/H4bvHx8aEeCQDQDIU8QOnp6brttts0ZMgQpaWl6d1339Xx48f15ptv1nt8ZmamqqqqfLcDBw6EeiQAQDPU6J8O6Natm66++mqVlpbW+7jb7Zbb7W7sMQAAzUyj/x7QiRMnVFZWptjY2MZ+KgBACxLyAC1YsEB5eXnat2+f/vGPf2jKlClq37697rzzzlA/FQCgBQv5j+AOHjyoO++8U8eOHVPPnj01ZswYFRYWqmfPnqF+KgBAC+ZyHMexHuLHvF6vPB6PUjRJHVxh1uPgAk5OSQp4TcLCLwJe83HhwIDXlE1bE/CapnTPV2MDXhPMeQhWcz5/wZy7ymR+vaMpfe+cUa62qKqqShEREQ0ex15wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJNiNF0KILGt5ksCHr+uQ3wiRtQ1rcddYjXFBTbU4bzGsomA1MJTYxDRabkQIAmjUCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY6GA9AOy9d2i39QgX1HfDrIDXxOUHt8l7l5yioNYhuHNXmRP489xTEPjO1sHuwt53RdO89trq644rIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABJuRNmMnpyQFvOZ/V73YCJOETjAbi/abV9gIk6Clqkz2BrwmmA1MJals2prAn2tU4M8VzKasrQFXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACTYjbcYOjXVZj3BBbCyKliKYDUwlSYcCX7KuT37Aa66f8tuA13TJKQp4TXPDFRAAwAQBAgCYCDhA+fn5uvnmmxUXFyeXy6XNmzf7Pe44jhYtWqTY2Fh17txZqampKikpCdW8AIBWIuAA1dTUaOjQoVq1alW9jy9btkzPPvus1qxZo6KiInXt2lVpaWk6derUJQ8LAGg9Av4QQnp6utLT0+t9zHEcrVy5Uo8//rgmTZokSVq3bp2io6O1efNm3XHHHZc2LQCg1Qjpe0Dl5eWqqKhQamqq7z6Px6OkpCQVFBTUu6a2tlZer9fvBgBo/UIaoIqKCklSdHS03/3R0dG+x34qKytLHo/Hd4uPjw/lSACAZsr8U3CZmZmqqqry3Q4cOGA9EgCgCYQ0QDExMZKkyspKv/srKyt9j/2U2+1WRESE3w0A0PqFNEAJCQmKiYnRtm3bfPd5vV4VFRUpOTk5lE8FAGjhAv4U3IkTJ1RaWur7ury8XLt371ZkZKR69+6tuXPn6sknn9RVV12lhIQEPfHEE4qLi9PkyZNDOTcAoIULOEA7d+7UuHHjfF/Pnz9fkjR9+nRlZ2dr4cKFqqmp0f3336/jx49rzJgx2rp1qzp16hS6qQEALZ7LcRzHeogf83q98ng8StEkdXCFWY9jqnTFqIDXlE1bE/Cae74aG/Aa6RI2eARaiJNTkgJek7Dwi0aY5HzN+b9/3ztnlKstqqqquuD7+uafggMAtE0ECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEfA/x4CmM3rU503yPOXLrglqXRcVhXgSoHnpkhP4a/zjsU2zi32argt4TXPDFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYILNSJuxdX3ym+R5gtlwEQAuFVdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJNiNtxu75amzAa5pqA1MAuFRcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJtiMtBn7uHBg4IvYjBQwVTZtjfUILQZXQAAAEwQIAGAi4ADl5+fr5ptvVlxcnFwulzZv3uz3+IwZM+RyufxuEydODNW8AIBWIuAA1dTUaOjQoVq1alWDx0ycOFGHDx/23V5//fVLGhIA0PoE/CGE9PR0paenX/AYt9utmJiYoIcCALR+jfIeUG5urqKiotS/f3/Nnj1bx44da/DY2tpaeb1evxsAoPULeYAmTpyodevWadu2bXrqqaeUl5en9PR0nT17tt7js7Ky5PF4fLf4+PhQjwQAaIZC/ntAd9xxh+/PgwcP1pAhQ9S3b1/l5uZq/Pjx5x2fmZmp+fPn+772er1ECADagEb/GHZiYqJ69Oih0tLSeh93u92KiIjwuwEAWr9GD9DBgwd17NgxxcbGNvZTAQBakIB/BHfixAm/q5ny8nLt3r1bkZGRioyM1NKlSzV16lTFxMSorKxMCxcuVL9+/ZSWlhbSwQEALVvAAdq5c6fGjRvn+/qH92+mT5+u1atXa8+ePXrllVd0/PhxxcXFacKECfrDH/4gt9sduqkBAC1ewAFKSUmR4zgNPv7ee+9d0kAA0FycnJIUxKrdAa/ou2FWwGv6qTDgNc0Ne8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARMj/SW60PKUrRgW1rt+8lr8bL3AhCQu/aJLnaav/XeIKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwWakzVgwGxTeM2pswGvKpq0JeI0kXZ//24DXdMkpCuq5gEsRXRAR1Lp1ffIDXtN3w6yA1/QTm5ECANBkCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATbEbaylQmewNfdCi45/rfVS8GvOaehYFvlhrU3wktQumKUQGvGT3q84DXBLOpaLCC2US4reIKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwWak0PUZvw1qXTCbkQa1KWQQm6Xe81Xgm55K0seFA4NaF6hgNqwMZuPOYDXdhp+7g1jTdPpumBXwmn5iM9KfiysgAIAJAgQAMBFQgLKysjRixAiFh4crKipKkydPVnFxsd8xp06dUkZGhrp3767LLrtMU6dOVWVlZUiHBgC0fAEFKC8vTxkZGSosLNT777+vM2fOaMKECaqpqfEdM2/ePL399tvauHGj8vLydOjQId1yyy0hHxwA0LIF9CGErVu3+n2dnZ2tqKgo7dq1S2PHjlVVVZVeeuklrV+/XjfeeKMkae3atbrmmmtUWFioUaOa7k1UAEDzdknvAVVVVUmSIiMjJUm7du3SmTNnlJqa6jtmwIAB6t27twoKCur9HrW1tfJ6vX43AEDrF3SA6urqNHfuXI0ePVqDBg2SJFVUVKhjx47q1q2b37HR0dGqqKio9/tkZWXJ4/H4bvHx8cGOBABoQYIOUEZGhvbu3as33njjkgbIzMxUVVWV73bgwIFL+n4AgJYhqF9EnTNnjt555x3l5+erV69evvtjYmJ0+vRpHT9+3O8qqLKyUjExMfV+L7fbLbfbHcwYAIAWLKArIMdxNGfOHOXk5Gj79u1KSEjwe3zYsGEKCwvTtm3bfPcVFxdr//79Sk5ODs3EAIBWIaAroIyMDK1fv15btmxReHi4730dj8ejzp07y+Px6L777tP8+fMVGRmpiIgIPfjgg0pOTuYTcAAAPwEFaPXq1ZKklJQUv/vXrl2rGTNmSJJWrFihdu3aaerUqaqtrVVaWppeeOGFkAwLAGg9XI7jONZD/JjX65XH41GKJqmDK8x6HFxAMJtjlk1b0wiToC0JZqPZ8mXXBPVcXXKKglrX1n3vnFGutqiqqkoRERENHsdecAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBbtho9oLZdXv0qM+Deq51ffKDWofg9N0wK+A1/eYVNsIkCCV2wwYANGsECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIkO1gMAFxPM5pOVQT5Xmq4LcmVgTk5JCnjNobGuRpgkdOLyA9/XuF8OG4u2ZVwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm2IwUMNAlpyjgNf1yGmEQwBBXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEQAHKysrSiBEjFB4erqioKE2ePFnFxcV+x6SkpMjlcvndZs2aFdKhAQAtX0ABysvLU0ZGhgoLC/X+++/rzJkzmjBhgmpqavyOmzlzpg4fPuy7LVu2LKRDAwBavoD+RdStW7f6fZ2dna2oqCjt2rVLY8eO9d3fpUsXxcTEhGZCAECrdEnvAVVVVUmSIiMj/e5/7bXX1KNHDw0aNEiZmZk6efJkg9+jtrZWXq/X7wYAaP0CugL6sbq6Os2dO1ejR4/WoEGDfPffdddd6tOnj+Li4rRnzx49+uijKi4u1qZNm+r9PllZWVq6dGmwYwAAWiiX4zhOMAtnz56tv//97/roo4/Uq1evBo/bvn27xo8fr9LSUvXt2/e8x2tra1VbW+v72uv1Kj4+XimapA6usGBGAwAY+t45o1xtUVVVlSIiIho8LqgroDlz5uidd95Rfn7+BeMjSUlJSZLUYIDcbrfcbncwYwAAWrCAAuQ4jh588EHl5OQoNzdXCQkJF12ze/duSVJsbGxQAwIAWqeAApSRkaH169dry5YtCg8PV0VFhSTJ4/Goc+fOKisr0/r16/WrX/1K3bt31549ezRv3jyNHTtWQ4YMaZS/AACgZQroPSCXy1Xv/WvXrtWMGTN04MAB/eY3v9HevXtVU1Oj+Ph4TZkyRY8//vgFfw74Y16vVx6Ph/eAAKCFapT3gC7Wqvj4eOXl5QXyLQEAbRR7wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHSwHuCnHMeRJH2vM5JjPAwAIGDf64yk//7veUOaXYCqq6slSR/pXeNJAACXorq6Wh6Pp8HHXc7FEtXE6urqdOjQIYWHh8vlcvk95vV6FR8frwMHDigiIsJoQnuch3M4D+dwHs7hPJzTHM6D4ziqrq5WXFyc2rVr+J2eZncF1K5dO/Xq1euCx0RERLTpF9gPOA/ncB7O4Tycw3k4x/o8XOjK5wd8CAEAYIIAAQBMtKgAud1uLV68WG6323oUU5yHczgP53AezuE8nNOSzkOz+xACAKBtaFFXQACA1oMAAQBMECAAgAkCBAAwQYAAACZaTIBWrVqlK6+8Up06dVJSUpJ27NhhPVKTW7JkiVwul99twIAB1mM1uvz8fN18882Ki4uTy+XS5s2b/R53HEeLFi1SbGysOnfurNTUVJWUlNgM24gudh5mzJhx3utj4sSJNsM2kqysLI0YMULh4eGKiorS5MmTVVxc7HfMqVOnlJGRoe7du+uyyy7T1KlTVVlZaTRx4/g55yElJeW818OsWbOMJq5fiwjQhg0bNH/+fC1evFiffvqphg4dqrS0NB05csR6tCZ37bXX6vDhw77bRx99ZD1So6upqdHQoUO1atWqeh9ftmyZnn32Wa1Zs0ZFRUXq2rWr0tLSdOrUqSaetHFd7DxI0sSJE/1eH6+//noTTtj48vLylJGRocLCQr3//vs6c+aMJkyYoJqaGt8x8+bN09tvv62NGzcqLy9Phw4d0i233GI4dej9nPMgSTNnzvR7PSxbtsxo4gY4LcDIkSOdjIwM39dnz5514uLinKysLMOpmt7ixYudoUOHWo9hSpKTk5Pj+7qurs6JiYlxnn76ad99x48fd9xut/P6668bTNg0fnoeHMdxpk+f7kyaNMlkHitHjhxxJDl5eXmO45z7zz4sLMzZuHGj75gvvvjCkeQUFBRYjdnofnoeHMdxbrjhBuehhx6yG+pnaPZXQKdPn9auXbuUmprqu69du3ZKTU1VQUGB4WQ2SkpKFBcXp8TERN19993av3+/9UimysvLVVFR4ff68Hg8SkpKapOvj9zcXEVFRal///6aPXu2jh07Zj1So6qqqpIkRUZGSpJ27dqlM2fO+L0eBgwYoN69e7fq18NPz8MPXnvtNfXo0UODBg1SZmamTp48aTFeg5rdbtg/dfToUZ09e1bR0dF+90dHR+vLL780mspGUlKSsrOz1b9/fx0+fFhLly7V9ddfr7179yo8PNx6PBMVFRWSVO/r44fH2oqJEyfqlltuUUJCgsrKyvTYY48pPT1dBQUFat++vfV4IVdXV6e5c+dq9OjRGjRokKRzr4eOHTuqW7dufse25tdDfedBku666y716dNHcXFx2rNnjx599FEVFxdr06ZNhtP6a/YBwn+lp6f7/jxkyBAlJSWpT58+evPNN3XfffcZTobm4I477vD9efDgwRoyZIj69u2r3NxcjR8/3nCyxpGRkaG9e/e2ifdBL6Sh83D//ff7/jx48GDFxsZq/PjxKisrU9++fZt6zHo1+x/B9ejRQ+3btz/vUyyVlZWKiYkxmqp56Natm66++mqVlpZaj2Lmh9cAr4/zJSYmqkePHq3y9TFnzhy98847+vDDD/3+/bCYmBidPn1ax48f9zu+tb4eGjoP9UlKSpKkZvV6aPYB6tixo4YNG6Zt27b57qurq9O2bduUnJxsOJm9EydOqKysTLGxsdajmElISFBMTIzf68Pr9aqoqKjNvz4OHjyoY8eOtarXh+M4mjNnjnJycrR9+3YlJCT4PT5s2DCFhYX5vR6Ki4u1f//+VvV6uNh5qM/u3bslqXm9Hqw/BfFzvPHGG47b7Xays7Odzz//3Ln//vudbt26ORUVFdajNamHH37Yyc3NdcrLy52PP/7YSU1NdXr06OEcOXLEerRGVV1d7Xz22WfOZ5995khyli9f7nz22WfOV1995TiO4/zxj390unXr5mzZssXZs2ePM2nSJCchIcH57rvvjCcPrQudh+rqamfBggVOQUGBU15e7nzwwQfOL3/5S+eqq65yTp06ZT16yMyePdvxeDxObm6uc/jwYd/t5MmTvmNmzZrl9O7d29m+fbuzc+dOJzk52UlOTjacOvQudh5KS0ud3//+987OnTud8vJyZ8uWLU5iYqIzduxY48n9tYgAOY7jPPfcc07v3r2djh07OiNHjnQKCwutR2py06ZNc2JjY52OHTs6V1xxhTNt2jSntLTUeqxG9+GHHzqSzrtNnz7dcZxzH8V+4oknnOjoaMftdjvjx493iouLbYduBBc6DydPnnQmTJjg9OzZ0wkLC3P69OnjzJw5s9X9n7T6/v6SnLVr1/qO+e6775wHHnjAufzyy50uXbo4U6ZMcQ4fPmw3dCO42HnYv3+/M3bsWCcyMtJxu91Ov379nEceecSpqqqyHfwn+PeAAAAmmv17QACA1okAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJ/wOG+I9ODQG9hAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for example_data, example_label in train_loader:\n",
    "    example_image = example_data[0]\n",
    "    print(f\"input size: {example_image.size()}\")\n",
    "    example_image_numpy = example_image.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(example_image_numpy)\n",
    "    plt.title(f\"Label: {example_label[0]}\")\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.cov1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.cov2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.cov3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        # Update the input size for fc1\n",
    "        self.fc1 = nn.Linear(128 * 26 * 26, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.cov1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.cov2(x)\n",
    "        x = self.cov3(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)   # Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.8409\n",
      "Epoch: 1, Batch: 200, Loss: 0.5838\n",
      "Epoch: 1, Batch: 300, Loss: 0.4281\n",
      "Epoch: 1, Batch: 400, Loss: 0.3656\n",
      "Epoch: 1, Batch: 500, Loss: 0.3205\n",
      "Epoch: 1, Batch: 600, Loss: 0.3008\n",
      "Epoch: 2, Batch: 100, Loss: 0.3804\n",
      "Epoch: 2, Batch: 200, Loss: 0.2393\n",
      "Epoch: 2, Batch: 300, Loss: 0.1937\n",
      "Epoch: 2, Batch: 400, Loss: 0.1935\n",
      "Epoch: 2, Batch: 500, Loss: 0.1857\n",
      "Epoch: 2, Batch: 600, Loss: 0.1570\n",
      "Epoch: 3, Batch: 100, Loss: 0.2058\n",
      "Epoch: 3, Batch: 200, Loss: 0.1422\n",
      "Epoch: 3, Batch: 300, Loss: 0.1273\n",
      "Epoch: 3, Batch: 400, Loss: 0.1198\n",
      "Epoch: 3, Batch: 500, Loss: 0.1264\n",
      "Epoch: 3, Batch: 600, Loss: 0.1228\n",
      "Epoch: 4, Batch: 100, Loss: 0.1628\n",
      "Epoch: 4, Batch: 200, Loss: 0.0938\n",
      "Epoch: 4, Batch: 300, Loss: 0.1066\n",
      "Epoch: 4, Batch: 400, Loss: 0.1013\n",
      "Epoch: 4, Batch: 500, Loss: 0.0854\n",
      "Epoch: 4, Batch: 600, Loss: 0.0884\n",
      "Epoch: 5, Batch: 100, Loss: 0.1398\n",
      "Epoch: 5, Batch: 200, Loss: 0.0767\n",
      "Epoch: 5, Batch: 300, Loss: 0.0764\n",
      "Epoch: 5, Batch: 400, Loss: 0.0765\n",
      "Epoch: 5, Batch: 500, Loss: 0.0743\n",
      "Epoch: 5, Batch: 600, Loss: 0.0720\n",
      "Epoch: 6, Batch: 100, Loss: 0.1074\n",
      "Epoch: 6, Batch: 200, Loss: 0.0651\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i , data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 100:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
