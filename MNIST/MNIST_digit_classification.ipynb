{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self,csv_file,transform=None,is_test=False):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data_frame.iloc[index]\n",
    "\n",
    "        if self.is_test:\n",
    "            image = item.values.reshape(28,28).astype(np.uint8)\n",
    "            label = None\n",
    "        else:\n",
    "            image = item[1:].values.reshape(28,28).astype(np.uint8)\n",
    "            label = item.iloc[0]\n",
    "\n",
    "        image = transforms.ToPILImage()(image)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_test:\n",
    "            return image\n",
    "        else:\n",
    "            return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomRotation(15),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5),),\n",
    "     transforms.Grayscale(1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomMNISTDataset(csv_file='train.csv',transform=transform,is_test=False)\n",
    "test_dataset = CustomMNISTDataset(csv_file='test.csv',transform=transform,is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 42003 Test Size: 28000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Size: {len(train_dataset)} Test Size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.9922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000,  0.0745,  0.5059, -0.3255,\n",
       "           -0.4353,  0.1843, -0.7490, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.8588, -0.7647,  0.0745,  0.9922,  0.9922,  0.7020,\n",
       "            0.9294,  0.9922,  0.8118, -0.5765, -0.8824, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.3255,  0.9608,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922, -0.1843, -0.3333, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8980,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.3412,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8745,  0.4039,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922, -0.1451, -0.3490,\n",
       "            0.5608, -0.7725,  0.5686,  0.9922,  0.9922,  0.9922,  0.6627,\n",
       "           -0.4039, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4353,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.1529, -0.6471, -1.0000,\n",
       "           -0.9137, -0.7725,  0.0039,  0.9765,  0.9922,  0.9922,  0.9922,\n",
       "            0.2000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5216,  0.4980,\n",
       "            0.9922,  0.9922,  0.5843,  0.1529, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -0.3490,  0.9922,  0.9922,  0.9922,\n",
       "            0.2000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3490,  0.9922,\n",
       "            0.9922, -0.3020, -0.4745, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.8039,  0.8824,  0.9922,\n",
       "            0.9922,  0.7569, -0.9059, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.9922,  0.3647,  0.9922,\n",
       "            0.9922, -0.7725, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3020,  0.9922,\n",
       "            0.9922,  0.9922, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6314,  0.9922,\n",
       "            0.9922,  0.8824, -0.8118, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4118,  0.9922,\n",
       "            0.9922,  0.9922, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3725,  0.9922,\n",
       "            0.9922,  0.4588, -0.9451, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6235,  0.9922,\n",
       "            0.9922,  0.9922, -0.8667, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4980,  0.9922,\n",
       "            0.9922,  0.9922, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.6392,\n",
       "            0.9922,  0.9922,  0.1765, -0.9922, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.8902,  0.8196,  0.9922,\n",
       "            0.9922,  0.9922, -0.7725, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8745,  0.6392,\n",
       "            0.9922,  0.9216, -0.7569, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922, -0.7725, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.8353,  0.2627,  0.9922,\n",
       "            0.9922,  0.3412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9843,  0.2784,\n",
       "            0.9922,  0.9922,  0.9922,  0.5686, -0.9059, -0.4824, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -0.6235,  0.6392,  0.9922,  0.9922,\n",
       "            0.9922, -0.3255, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.2627,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.5843, -0.4824, -0.6235,\n",
       "           -0.6235, -0.7333, -0.6784,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.8745, -0.3255, -0.9137, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8824,\n",
       "            0.6157,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.8275,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "           -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.5294, -0.3255,  0.9059,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9059,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -0.1059,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  1.0000,  0.1451, -0.8510, -0.8824,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -0.8980,  0.4275,  0.9922,  0.1451,\n",
       "            0.9922,  1.0000,  0.9922, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9373, -0.4039, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False) # num_workers=2 slows down the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for example_data, example_label in train_loader:\n",
    "    example_image = example_data[0]\n",
    "    print(f\"input size: {example_image.size()}\")\n",
    "    example_image_numpy = example_image.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(example_image_numpy)\n",
    "    plt.title(f\"Label: {example_label[0]}\")\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)   # Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 2.3026\n",
      "Epoch: 2, Batch: 100, Loss: 3.2334\n",
      "Epoch: 3, Batch: 100, Loss: 2.8678\n",
      "Epoch: 4, Batch: 100, Loss: 0.8494\n",
      "Epoch: 5, Batch: 100, Loss: 0.6771\n",
      "Epoch: 6, Batch: 100, Loss: 0.4577\n",
      "Epoch: 7, Batch: 100, Loss: 0.3976\n",
      "Epoch: 8, Batch: 100, Loss: 0.3666\n",
      "Epoch: 9, Batch: 100, Loss: 0.2716\n",
      "Epoch: 10, Batch: 100, Loss: 0.3007\n",
      "Epoch: 11, Batch: 100, Loss: 0.2973\n",
      "Epoch: 12, Batch: 100, Loss: 0.2156\n",
      "Epoch: 13, Batch: 100, Loss: 0.1827\n",
      "Epoch: 14, Batch: 100, Loss: 0.1686\n",
      "Epoch: 15, Batch: 100, Loss: 0.1578\n",
      "Epoch: 16, Batch: 100, Loss: 0.1463\n",
      "Epoch: 17, Batch: 100, Loss: 0.1299\n",
      "Epoch: 18, Batch: 100, Loss: 0.1352\n",
      "Epoch: 19, Batch: 100, Loss: 0.1262\n",
      "Epoch: 20, Batch: 100, Loss: 0.1174\n",
      "Epoch: 21, Batch: 100, Loss: 0.1177\n",
      "Epoch: 22, Batch: 100, Loss: 0.1215\n",
      "Epoch: 23, Batch: 100, Loss: 0.1049\n",
      "Epoch: 24, Batch: 100, Loss: 0.1025\n",
      "Epoch: 25, Batch: 100, Loss: 0.0985\n",
      "Epoch: 26, Batch: 100, Loss: 0.1037\n",
      "Epoch: 27, Batch: 100, Loss: 0.0885\n",
      "Epoch: 28, Batch: 100, Loss: 0.0865\n",
      "Epoch: 29, Batch: 100, Loss: 0.0819\n",
      "Epoch: 30, Batch: 100, Loss: 0.0780\n",
      "Epoch: 31, Batch: 100, Loss: 0.0793\n",
      "Epoch: 32, Batch: 100, Loss: 0.0711\n",
      "Epoch: 33, Batch: 100, Loss: 0.0750\n",
      "Epoch: 34, Batch: 100, Loss: 0.0709\n",
      "Epoch: 35, Batch: 100, Loss: 0.0671\n",
      "Epoch: 36, Batch: 100, Loss: 0.0654\n",
      "Epoch: 37, Batch: 100, Loss: 0.0664\n",
      "Epoch: 38, Batch: 100, Loss: 0.0581\n",
      "Epoch: 39, Batch: 100, Loss: 0.0613\n",
      "Epoch: 40, Batch: 100, Loss: 0.0577\n",
      "Epoch: 41, Batch: 100, Loss: 0.0952\n",
      "Epoch: 42, Batch: 100, Loss: 0.0585\n",
      "Epoch: 43, Batch: 100, Loss: 0.0585\n",
      "Epoch: 44, Batch: 100, Loss: 0.0570\n",
      "Epoch: 45, Batch: 100, Loss: 0.0542\n",
      "Epoch: 46, Batch: 100, Loss: 0.0534\n",
      "Epoch: 47, Batch: 100, Loss: 0.0525\n",
      "Epoch: 48, Batch: 100, Loss: 0.0499\n",
      "Epoch: 49, Batch: 100, Loss: 0.0484\n",
      "Epoch: 50, Batch: 100, Loss: 0.0479\n",
      "Epoch: 51, Batch: 100, Loss: 0.0470\n",
      "Epoch: 52, Batch: 100, Loss: 0.0441\n",
      "Epoch: 53, Batch: 100, Loss: 0.0472\n",
      "Epoch: 54, Batch: 100, Loss: 0.0456\n",
      "Epoch: 55, Batch: 100, Loss: 0.0385\n",
      "Epoch: 56, Batch: 100, Loss: 0.0407\n",
      "Epoch: 57, Batch: 100, Loss: 0.1331\n",
      "Epoch: 58, Batch: 100, Loss: 0.0554\n",
      "Epoch: 59, Batch: 100, Loss: 0.0471\n",
      "Epoch: 60, Batch: 100, Loss: 0.0443\n",
      "Epoch: 61, Batch: 100, Loss: 0.0414\n",
      "Epoch: 62, Batch: 100, Loss: 0.0395\n",
      "Epoch: 63, Batch: 100, Loss: 0.0383\n",
      "Epoch: 64, Batch: 100, Loss: 0.0364\n",
      "Epoch: 65, Batch: 100, Loss: 0.0352\n",
      "Epoch: 66, Batch: 100, Loss: 0.0380\n",
      "Epoch: 67, Batch: 100, Loss: 0.0314\n",
      "Epoch: 68, Batch: 100, Loss: 0.0336\n",
      "Epoch: 69, Batch: 100, Loss: 0.0334\n",
      "Epoch: 70, Batch: 100, Loss: 0.0385\n",
      "Epoch: 71, Batch: 100, Loss: 0.0450\n",
      "Epoch: 72, Batch: 100, Loss: 0.0330\n",
      "Epoch: 73, Batch: 100, Loss: 0.0300\n",
      "Epoch: 74, Batch: 100, Loss: 0.0323\n",
      "Epoch: 75, Batch: 100, Loss: 0.0299\n",
      "Epoch: 76, Batch: 100, Loss: 0.0302\n",
      "Epoch: 77, Batch: 100, Loss: 0.2120\n",
      "Epoch: 78, Batch: 100, Loss: 0.0660\n",
      "Epoch: 79, Batch: 100, Loss: 0.0492\n",
      "Epoch: 80, Batch: 100, Loss: 0.0424\n",
      "Epoch: 81, Batch: 100, Loss: 0.0417\n",
      "Epoch: 82, Batch: 100, Loss: 0.0369\n",
      "Epoch: 83, Batch: 100, Loss: 0.0351\n",
      "Epoch: 84, Batch: 100, Loss: 0.0332\n",
      "Epoch: 85, Batch: 100, Loss: 0.0330\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150\n",
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i , data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 100:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model \n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
